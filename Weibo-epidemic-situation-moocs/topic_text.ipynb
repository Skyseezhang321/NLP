{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/result.csv',encoding=\"utf8\",error_bad_lines=False, sep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[['微博','老师or学生']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>微博</th>\n",
       "      <th>老师or学生</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>#延假期不停学##停课不停学#大家有问题快来咨询，老师在线帮你解答~</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>#延假期不停学##停课不停学#闷在家的正确姿势#教育在行动#</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>#延假期不停学##停课不停学#假期不停学</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>#延假期不停学##停课不停学#假期不停学</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>//@头条教育:#延假期不停学##停课不停学#大家有问题快来咨询，老师在线帮你解答~</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385172</td>\n",
       "      <td>#朗阁温馨提示#请细细看这9张图❗️现在不出门非常关键❗️居家隔离❗️好好做“D”❗️继续做...</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385936</td>\n",
       "      <td>学习了//@刘码露:实用//@江南大野花:存了了解分类//@沐非://@管鑫Sa:协和医生写...</td>\n",
       "      <td>leaner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385947</td>\n",
       "      <td>转发学习//@shly_yyy:转首页//@眼儿媚滴春://@沐非://@管鑫Sa:协和医生...</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385951</td>\n",
       "      <td>学习//@刘码露:实用//@江南大野花:存了了解分类//@沐非://@管鑫Sa:协和医生写的...</td>\n",
       "      <td>leaner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385954</td>\n",
       "      <td>学习一下//@管鑫Sa:协和医生写的居家消毒小贴士，推荐。</td>\n",
       "      <td>leaner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       微博  老师or学生\n",
       "126                    #延假期不停学##停课不停学#大家有问题快来咨询，老师在线帮你解答~     tea\n",
       "128                        #延假期不停学##停课不停学#闷在家的正确姿势#教育在行动#     tea\n",
       "129                                  #延假期不停学##停课不停学#假期不停学     tea\n",
       "130                                  #延假期不停学##停课不停学#假期不停学     tea\n",
       "136            //@头条教育:#延假期不停学##停课不停学#大家有问题快来咨询，老师在线帮你解答~     tea\n",
       "...                                                   ...     ...\n",
       "385172  #朗阁温馨提示#请细细看这9张图❗️现在不出门非常关键❗️居家隔离❗️好好做“D”❗️继续做...     tea\n",
       "385936  学习了//@刘码露:实用//@江南大野花:存了了解分类//@沐非://@管鑫Sa:协和医生写...  leaner\n",
       "385947  转发学习//@shly_yyy:转首页//@眼儿媚滴春://@沐非://@管鑫Sa:协和医生...     tea\n",
       "385951  学习//@刘码露:实用//@江南大野花:存了了解分类//@沐非://@管鑫Sa:协和医生写的...  leaner\n",
       "385954                      学习一下//@管鑫Sa:协和医生写的居家消毒小贴士，推荐。  leaner\n",
       "\n",
       "[1215 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = data['微博'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去停用词\n",
    "stop_word_path = './data/stopword.txt'\n",
    "stop_word_list = [sw.replace('\\n','') for sw in open(stop_word_path).readlines()]\n",
    "\n",
    "def preprocess_text(content_lines,sentences):\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs = jieba.lcut(line)\n",
    "            segs = list(filter(lambda x: x not in stop_word_list,segs))\n",
    "            sentences.append(' '.join(segs))#分完词后 用空格串起来 且和label合并为一个元组\n",
    "        except Exception as e:\n",
    "            print(line)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练数据\n",
    "sentences = []\n",
    "preprocess_text(content,sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in sentences:\n",
    "    temp = []\n",
    "    line_list = line.split(' ')\n",
    "    for item in line_list:\n",
    "        temp.append(item)\n",
    "    train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建词频矩阵，训练LDA模型\n",
    "\"\"\"构建词频矩阵，训练LDA模型\"\"\"\n",
    "dictionary = corpora.Dictionary(train) #构建词典\n",
    "## corpus是把每条新闻ID化后的结果，每个元素是新闻中的每个词语，在字典中的ID和频率\n",
    "corpus = [dictionary.doc2bow(text) for text in train] #文本id化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_list = lda.print_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10个主题的单词分布为：\n",
      "\n",
      "(0, '0.011*\"🙏\" + 0.010*\"_\" + 0.009*\"网上\" + 0.008*\"学习\" + 0.008*\"找\" + 0.008*\"希望\" + 0.008*\"没有\" + 0.007*\"资源\" + 0.007*\"不\" + 0.007*\"…\"')\n",
      "(1, '0.020*\"都\" + 0.018*\"人\" + 0.011*\"不要\" + 0.009*\"学习\" + 0.009*\"在家\" + 0.009*\"视频\" + 0.008*\"不\" + 0.007*\"_\" + 0.006*\"找\" + 0.006*\"冻毙\"')\n",
      "(2, '0.063*\"转发\" + 0.018*\"##\" + 0.017*\"都\" + 0.015*\"被删\" + 0.015*\"山西\" + 0.014*\"专业\" + 0.012*\"少女\" + 0.012*\"记得\" + 0.010*\"疫情\" + 0.010*\"已经\"')\n",
      "(3, '0.012*\"被删\" + 0.012*\"转发\" + 0.011*\"🙏\" + 0.010*\"_\" + 0.009*\"少女\" + 0.008*\"视频\" + 0.008*\"学习\" + 0.008*\"一次\" + 0.008*\"资源\" + 0.008*\"看到\"')\n",
      "(4, '0.014*\"转发\" + 0.006*\"被删\" + 0.006*\"…\" + 0.006*\"不\" + 0.006*\"都\" + 0.006*\"不要\" + 0.006*\"转\" + 0.006*\"大家\" + 0.005*\"没有\" + 0.004*\"老虎机\"')\n",
      "(5, '0.018*\"公务员\" + 0.011*\"##\" + 0.010*\"学习\" + 0.009*\"疫情\" + 0.009*\"说\" + 0.009*\"没有\" + 0.009*\"山西\" + 0.009*\"专业\" + 0.008*\"资源\" + 0.008*\"网上\"')\n",
      "(6, '0.012*\"🙏\" + 0.011*\"_\" + 0.006*\"转\" + 0.006*\"学习\" + 0.005*\"小\" + 0.005*\"太\" + 0.005*\"记者\" + 0.005*\"转发\" + 0.005*\"证据\" + 0.005*\"新生代\"')\n",
      "(7, '0.028*\"🙏\" + 0.014*\"_\" + 0.011*\"好\" + 0.010*\"去世\" + 0.009*\"说\" + 0.008*\"网上\" + 0.007*\"转发\" + 0.007*\"都\" + 0.007*\"不\" + 0.006*\"转\"')\n",
      "(8, '0.070*\"转发\" + 0.010*\"医生\" + 0.009*\"在线\" + 0.008*\"快\" + 0.007*\"网上\" + 0.007*\"去世\" + 0.007*\"说\" + 0.006*\"出来\" + 0.006*\"都\" + 0.006*\"李亮\"')\n",
      "(9, '0.018*\"被删\" + 0.017*\"转发\" + 0.016*\"医生\" + 0.014*\"里\" + 0.014*\"训诫\" + 0.014*\"…\" + 0.013*\"网上\" + 0.012*\"人们\" + 0.012*\"得到\" + 0.012*\"外科\"')\n"
     ]
    }
   ],
   "source": [
    "print(\"10个主题的单词分布为：\\n\")\n",
    "for topic in topic_list:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1封邮件的大致内容为：\n",
      " ['延', '假期', '不停', '学', '##', '停课', '不停', '学', '大家', '问题', '快', '咨询', '老师', '在线', '帮', '解答', '~'] \n",
      "\n",
      "第1封邮件的主题分布为：\n",
      " [(8, 0.9499897)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"第三步：查看某封邮件所属的主题\"\"\"\n",
    "print(\"第1封邮件的大致内容为：\\n\",train[0],'\\n')\n",
    "topic = lda.get_document_topics(corpus[0])\n",
    "print(\"第1封邮件的主题分布为：\\n\",topic,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
      "\u001b[K     |██▍                             | 16.6MB 26kB/s eta 2:06:289     |█▎                              | 8.6MB 30kB/s eta 1:53:39\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 304, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1822, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1622, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 304, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1822, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1622, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 304, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1822, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1622, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 304, in recv_into\n",
      "    return self.connection.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1822, in recv_into\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\", line 1622, in _raise_ssl_error\n",
      "    raise WantReadError()\n",
      "OpenSSL.SSL.WantReadError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 397, in _error_catcher\n",
      "    yield\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 479, in read\n",
      "    data = self._fp.read(amt)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/cachecontrol/filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/http/client.py\", line 457, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/http/client.py\", line 501, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/socket.py\", line 589, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 319, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 319, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 319, in recv_into\n",
      "    return self.recv_into(*args, **kwargs)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/contrib/pyopenssl.py\", line 317, in recv_into\n",
      "    raise timeout('The read operation timed out')\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 188, in main\n",
      "    status = self.run(options, args)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 345, in run\n",
      "    resolver.resolve(requirement_set)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/legacy_resolve.py\", line 196, in resolve\n",
      "    self._resolve_one(requirement_set, req)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/legacy_resolve.py\", line 359, in _resolve_one\n",
      "    abstract_dist = self._get_abstract_dist_for(req_to_install)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/legacy_resolve.py\", line 307, in _get_abstract_dist_for\n",
      "    self.require_hashes\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/prepare.py\", line 199, in prepare_linked_requirement\n",
      "    progress_bar=self.progress_bar\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/download.py\", line 1064, in unpack_url\n",
      "    progress_bar=progress_bar\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/download.py\", line 924, in unpack_http_url\n",
      "    progress_bar)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/download.py\", line 1152, in _download_http_url\n",
      "    _download_url(resp, link, content_file, hashes, progress_bar)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/download.py\", line 861, in _download_url\n",
      "    hashes.check_against_chunks(downloaded_chunks)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/utils/hashes.py\", line 75, in check_against_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/download.py\", line 829, in written_chunks\n",
      "    for chunk in chunks:\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/utils/ui.py\", line 156, in iter\n",
      "    for x in it:\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/download.py\", line 818, in resp_read\n",
      "    decode_content=False):\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 531, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 496, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/urllib3/response.py\", line 402, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
