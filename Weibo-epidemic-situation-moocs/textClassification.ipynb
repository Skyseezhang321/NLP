{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train_test_data.csv',encoding=\"utf8\",error_bad_lines=False, sep=None)\n",
    "data=data[['content','target']]\n",
    "data = data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "data['target'] =data['target'].astype(\"int\")\n",
    "data = shuffle(data)#乱序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tea = data[data['target']==0]\n",
    "tea = tea['content'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaner = data[data['target']==1]\n",
    "leaner = leaner['content'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去停用词\n",
    "stop_word_path = './data/stopword.txt'\n",
    "stop_word_list = [sw.replace('\\n','') for sw in open(stop_word_path).readlines()]\n",
    "\n",
    "def preprocess_text(content_lines,sentences,category):\n",
    "    for line in content_lines:\n",
    "        try:\n",
    "            segs = jieba.lcut(line)\n",
    "            #segs = list(filter(lambda x: len(x)>1,segs))\n",
    "            segs = list(filter(lambda x: x not in stop_word_list,segs))\n",
    "            sentences.append((' '.join(segs),category))#分完词后 用空格串起来 且和label合并为一个元组\n",
    "        except Exception as e:\n",
    "            print(line)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成训练数据\n",
    "sentences = []\n",
    "preprocess_text(leaner,sentences,'leaner')\n",
    "preprocess_text(tea,sentences,'tea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x,y = zip(*sentences)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#交叉验证\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "def stratifiedFfold_cv(x,y,clf_class,folds=5,**kwargs):\n",
    "    folds = KFold(n_splits=folds, shuffle=True, random_state=seed)\n",
    "    y_pred = y[:]\n",
    "    for fold, (train_index, test_index) in enumerate(folds.split(x, y)):\n",
    "        x_train,x_test = x[train_index],x[test_index]\n",
    "        y_train = y[train_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifierSVM():\n",
    "    def __init__(self,classifier = SVC(kernel='linear')):#可以换内核\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,4),max_features=20000)\n",
    "    def features(self,X):\n",
    "        return self.vectorizer.transform(X)\n",
    "    def fit(self,X,y):\n",
    "        self.vectorizer.fit(X)\n",
    "        self.classifier.fit(self.features(X),y)\n",
    "    def predict(self,X):\n",
    "        return self.classifier.predict(self.features([X]))\n",
    "    def score(self,X,y):\n",
    "        return self.classifier.score(self.features(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tea']\n",
      "0.8516624040920716\n"
     ]
    }
   ],
   "source": [
    "text_classifier = TextClassifierSVM()\n",
    "text_classifier.fit(x_train,y_train)\n",
    "print(text_classifier.predict('我是一个mooc的学习者'))\n",
    "print(text_classifier.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "####用于聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec=TfidfVectorizer(\n",
    "    analyzer='word', \n",
    "    ngram_range=(1,4),\n",
    "    max_features=20000\n",
    "    )\n",
    "vec.fit(x_train)                       #从新训练集fit特征\n",
    "\n",
    "'''\n",
    "使用TF-IDF提取特征，结果为0.8755\n",
    "'''\n",
    "tf_idf = vec.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取词袋模型中的所有词语\n",
    "word = vec.get_feature_names()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将tf-idf矩阵抽取出来，元素w[i][j]表示j词在i类文本中的tf-idf权重  \n",
    "weight = tf_idf.toarray()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca降维\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 800) # 初始化PCA  dimension=800 \n",
    "weight_of_dim = pca.fit_transform(weight) # 返回降维后的数据  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusterer = KMeans(n_clusters=10, init='k-means++') # 设置聚类模型 k=10\n",
    "y = clusterer.fit_predict(weight_of_dim) # 把weight矩阵扔进去fit一下,输出label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 1, ..., 2, 1, 3], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1173"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/exudingtao/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "####################------predict------###############\n",
    "data2 = pd.read_csv('./data/0121-0210 new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tea'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去停用词\n",
    "stop_word_path = './data/stopword.txt'\n",
    "stop_word_list = [sw.replace('\\n','') for sw in open(stop_word_path).readlines()]\n",
    "def predict_content(content_lines):\n",
    "    try:\n",
    "        segs = jieba.lcut(content_lines)\n",
    "        segs = list(filter(lambda x: x not in stop_word_list,segs))\n",
    "        word_list = ' '.join(segs)#分完词后 用空格串起来 且和label合并为一个元组\n",
    "        res = text_classifier.predict(word_list)[0]\n",
    "    except:\n",
    "        res = 'error'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data2['老师or学生'] = data2['微博'].apply(lambda x:predict_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv('./data/result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
